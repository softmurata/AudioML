{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPJbSuhgUGwZxwUdT94YO2B",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/softmurata/AudioML/blob/main/avatar/chatavatar.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Installation"
      ],
      "metadata": {
        "id": "jFEIKS9Mi_kR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q gradio\n",
        "!pip install -q sentence_transformers"
      ],
      "metadata": {
        "id": "c3lDSvG6jAph"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "wOhCuFq0BvXA"
      },
      "outputs": [],
      "source": [
        "# ユースケース1: 新規顧客獲得\n",
        "case1 = [\n",
        "    {\"Q\": \"営業: こんにちは、村田さん。弊社のサービスに興味を持っていただきありがとうございます。まず最初に、お手伝いできることや特にお困りごとはありますか？\",\n",
        "     \"A\": \"お客様: はい、最近村田さんに課題を抱えていて、それに対する解決策を模索しています。\"},\n",
        "    {\"Q\": \"営業: それは理解できます。お聞かせいただければと思いますが、現在の課題の具体的なポイントは何でしょうか？\",\n",
        "     \"A\": \"お客様: 村田さんが効率的に機能していないことが主な課題です。\"},\n",
        "    {\"Q\": \"営業: なるほど、それは重要なポイントですね。弊社のサービスは、村田さんの効率向上に特に焦点を当てており、その点でお手伝いできるかもしれません。どのような要件や期待をお持ちでしょうか？\",\n",
        "     \"A\": \"お客様: 具体的な要件としては、村田さんがスムーズに行えることと、村田さんの改善案があれば教えていただきたいです。\"}\n",
        "]\n",
        "\n",
        "# ユースケース2: 既存顧客へのアップセル\n",
        "case2 = [\n",
        "    {\"Q\": \"営業: お世話になっております、村田さん。これまでのご利用ありがとうございます。今回は、新たな機能やアップグレードについてお知らせがあります。お時間いただけますでしょうか？\",\n",
        "     \"A\": \"お客様: はい、どのような内容ですか？\"},\n",
        "    {\"Q\": \"営業: 弊社では最近、〇〇機能を追加しました。これにより、〇〇の利便性が向上し、業務の効率化が期待できます。ご興味がありましたら、詳細をご案内させていただけますか？\",\n",
        "     \"A\": \"お客様: 興味がありますね。具体的にどのような変更があるのでしょうか？\"},\n",
        "    {\"Q\": \"営業: それでは、〇〇機能の詳細や導入メリットについてお話しいたしますね。\",\n",
        "     \"A\": \"お客様: 聞きたいことがあれば質問させてください。\"}\n",
        "]\n",
        "\n",
        "# ユースケース3: フィードバック収集\n",
        "case3 = [\n",
        "    {\"Q\": \"営業: こんにちは、〇〇さん。ご愛顧いただきありがとうございます。今日は、弊社のサービスに関するフィードバックをお伺いしたく存じます。ご意見やご感想がありましたらお聞かせいただけますか？\",\n",
        "     \"A\": \"お客様: あまり大きな問題はないですが、時々〇〇に関する使い勝手が気になります。\"},\n",
        "    {\"Q\": \"営業: それは貴重なご意見ですね。具体的にどのような点が気になりましたか？\",\n",
        "     \"A\": \"お客様: 〇〇の操作が少し複雑で、もっと直感的になればいいなと思います。\"},\n",
        "    {\"Q\": \"営業: 了解しました。おっしゃる通り、使いやすさが重要ですね。今後の開発で改善できるように努めてまいります。他にも何かありましたらお気軽におっしゃってください。\",\n",
        "     \"A\": \"お客様: ありがとうございます。他には特に問題ないですが、改善点があれば随時お知らせいたします。\"}\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "import numpy as np\n",
        "import glob\n",
        "\n",
        "def cosine_similarity(v1, v2):\n",
        "    dot_product = np.dot(v1, v2)\n",
        "    magnitude_v1 = np.linalg.norm(v1)\n",
        "    magnitude_v2 = np.linalg.norm(v2)\n",
        "\n",
        "    if magnitude_v1 == 0 or magnitude_v2 == 0:\n",
        "        return 0\n",
        "    else:\n",
        "        return dot_product / (magnitude_v1 * magnitude_v2)\n",
        "\n",
        "\n",
        "model = SentenceTransformer('pkshatech/GLuCoSE-base-ja')\n",
        "\n",
        "questions = []\n",
        "for item in case1:\n",
        "  questions.append(item[\"Q\"])\n",
        "question_embeddings = model.encode(questions)\n",
        "\n",
        "videos = sorted(glob.glob(\"/content/case1/*.mp4\"))"
      ],
      "metadata": {
        "id": "WJb8VkYnSRTU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 音声入力ー＞文字起こしみたいなところもできるようにしておくといい？"
      ],
      "metadata": {
        "id": "GhPoD2SsYJE9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "import cv2\n",
        "\n",
        "blocks = gr.Blocks()\n",
        "\n",
        "message_history = []\n",
        "\n",
        "with blocks as demo:\n",
        "  with gr.Row():\n",
        "    gr.Markdown(\"## 営業トーク\")\n",
        "  with gr.Column():\n",
        "    with gr.Row():\n",
        "      video = gr.Video(label=\"Face Video\", autoplay=True)\n",
        "      chatbot = gr.Chatbot()\n",
        "    with gr.Row():\n",
        "      input = gr.Textbox(label=\"input text\", placeholder=\"input your text...\")\n",
        "      send_button = gr.Button(\"Send\")\n",
        "\n",
        "    def video_identify(query):\n",
        "      global message_history\n",
        "\n",
        "      message_history.append({\n",
        "          \"role\": \"user\",\n",
        "          \"content\": query\n",
        "      })\n",
        "\n",
        "      source_embeddings = model.encode([query])\n",
        "\n",
        "      cos_sim_value_list = []\n",
        "      for t in question_embeddings:\n",
        "        cos_sim_value = cosine_similarity(t, source_embeddings.reshape(-1))\n",
        "        cos_sim_value_list.append(cos_sim_value)\n",
        "\n",
        "      top_id = np.argsort(cos_sim_value_list)[::-1][0]\n",
        "\n",
        "      answer = case1[top_id][\"A\"]\n",
        "      video_path = videos[top_id]\n",
        "\n",
        "      message_history.append({\n",
        "          \"role\": \"assistant\",\n",
        "          \"content\": answer\n",
        "      })\n",
        "\n",
        "      return video_path\n",
        "\n",
        "    def chat_output():\n",
        "\n",
        "      return [(message_history[i][\"content\"], message_history[i + 1][\"content\"]) for i in range(0, len(message_history) - 1, 2)]\n",
        "\n",
        "\n",
        "    video.play(\n",
        "        chat_output,\n",
        "        inputs=[],\n",
        "        outputs=[chatbot]\n",
        "    )\n",
        "\n",
        "\n",
        "    send_button.click(\n",
        "        video_identify,\n",
        "        inputs=[input],\n",
        "        outputs=[video]\n",
        "    )\n",
        "\n",
        "\n",
        "\n",
        "demo.launch(debug=True)"
      ],
      "metadata": {
        "id": "uDlxwDuLQbFe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# case1\n",
        "case1 = [\n",
        "    {\"Q\": \"営業: こんにちは、村田さん。弊社のサービスに興味を持っていただきありがとうございます。まず最初に、お手伝いできることや特にお困りごとはありますか？\",\n",
        "     \"A\": \"お客様: はい、最近村田さんに課題を抱えていて、それに対する解決策を模索しています。\"},\n",
        "    {\"Q\": \"営業: それは理解できます。お聞かせいただければと思いますが、現在の課題の具体的なポイントは何でしょうか？\",\n",
        "     \"A\": \"お客様: 村田さんが効率的に機能していないことが主な課題です。\"},\n",
        "    {\"Q\": \"営業: なるほど、それは重要なポイントですね。弊社のサービスは、村田さんの効率向上に特に焦点を当てており、その点でお手伝いできるかもしれません。どのような要件や期待をお持ちでしょうか？\",\n",
        "     \"A\": \"お客様: 具体的な要件としては、村田さんがスムーズに行えることと、村田さんの改善案があれば教えていただきたいです。\"}\n",
        "]"
      ],
      "metadata": {
        "id": "Ij1Ytq8CUpGK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "音声入力デモ"
      ],
      "metadata": {
        "id": "bGdRvoMFYfPH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import gradio as gr\n",
        "import time\n",
        "import yt_dlp as youtube_dl\n",
        "from transformers import pipeline\n",
        "from transformers.pipelines.audio_utils import ffmpeg_read\n",
        "\n",
        "import tempfile\n",
        "import os\n",
        "\n",
        "MODEL_NAME = \"openai/whisper-large-v3\"\n",
        "BATCH_SIZE = 8\n",
        "FILE_LIMIT_MB = 1000\n",
        "YT_LENGTH_LIMIT_S = 3600  # limit to 1 hour YouTube files\n",
        "\n",
        "device = 0 if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "pipe = pipeline(\n",
        "    task=\"automatic-speech-recognition\",\n",
        "    model=MODEL_NAME,\n",
        "    chunk_length_s=30,\n",
        "    device=device,\n",
        ")\n",
        "\n",
        "def transcribe(inputs, task):\n",
        "    if inputs is None:\n",
        "        raise gr.Error(\"No audio file submitted! Please upload or record an audio file before submitting your request.\")\n",
        "\n",
        "    text = pipe(inputs, batch_size=BATCH_SIZE, generate_kwargs={\"task\": task}, return_timestamps=True)[\"text\"]\n",
        "    return  text\n",
        "\n",
        "\n",
        "def _return_yt_html_embed(yt_url):\n",
        "    video_id = yt_url.split(\"?v=\")[-1]\n",
        "    HTML_str = (\n",
        "        f'<center> <iframe width=\"500\" height=\"320\" src=\"https://www.youtube.com/embed/{video_id}\"> </iframe>'\n",
        "        \" </center>\"\n",
        "    )\n",
        "    return HTML_str\n",
        "\n",
        "def download_yt_audio(yt_url, filename):\n",
        "    info_loader = youtube_dl.YoutubeDL()\n",
        "\n",
        "    try:\n",
        "        info = info_loader.extract_info(yt_url, download=False)\n",
        "    except youtube_dl.utils.DownloadError as err:\n",
        "        raise gr.Error(str(err))\n",
        "\n",
        "    file_length = info[\"duration_string\"]\n",
        "    file_h_m_s = file_length.split(\":\")\n",
        "    file_h_m_s = [int(sub_length) for sub_length in file_h_m_s]\n",
        "\n",
        "    if len(file_h_m_s) == 1:\n",
        "        file_h_m_s.insert(0, 0)\n",
        "    if len(file_h_m_s) == 2:\n",
        "        file_h_m_s.insert(0, 0)\n",
        "    file_length_s = file_h_m_s[0] * 3600 + file_h_m_s[1] * 60 + file_h_m_s[2]\n",
        "\n",
        "    if file_length_s > YT_LENGTH_LIMIT_S:\n",
        "        yt_length_limit_hms = time.strftime(\"%HH:%MM:%SS\", time.gmtime(YT_LENGTH_LIMIT_S))\n",
        "        file_length_hms = time.strftime(\"%HH:%MM:%SS\", time.gmtime(file_length_s))\n",
        "        raise gr.Error(f\"Maximum YouTube length is {yt_length_limit_hms}, got {file_length_hms} YouTube video.\")\n",
        "\n",
        "    ydl_opts = {\"outtmpl\": filename, \"format\": \"worstvideo[ext=mp4]+bestaudio[ext=m4a]/best[ext=mp4]/best\"}\n",
        "\n",
        "    with youtube_dl.YoutubeDL(ydl_opts) as ydl:\n",
        "        try:\n",
        "            ydl.download([yt_url])\n",
        "        except youtube_dl.utils.ExtractorError as err:\n",
        "            raise gr.Error(str(err))\n",
        "\n",
        "\n",
        "def yt_transcribe(yt_url, task, max_filesize=75.0):\n",
        "    html_embed_str = _return_yt_html_embed(yt_url)\n",
        "\n",
        "    with tempfile.TemporaryDirectory() as tmpdirname:\n",
        "        filepath = os.path.join(tmpdirname, \"video.mp4\")\n",
        "        download_yt_audio(yt_url, filepath)\n",
        "        with open(filepath, \"rb\") as f:\n",
        "            inputs = f.read()\n",
        "\n",
        "    inputs = ffmpeg_read(inputs, pipe.feature_extractor.sampling_rate)\n",
        "    inputs = {\"array\": inputs, \"sampling_rate\": pipe.feature_extractor.sampling_rate}\n",
        "\n",
        "    text = pipe(inputs, batch_size=BATCH_SIZE, generate_kwargs={\"task\": task}, return_timestamps=True)[\"text\"]\n",
        "\n",
        "    return html_embed_str, text"
      ],
      "metadata": {
        "id": "Kqjl02kMY8kw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "\n",
        "blocks = gr.Blocks()\n",
        "\n",
        "with blocks as demo:\n",
        "  with gr.Row():\n",
        "    with gr.Column():\n",
        "      input_audio = gr.Audio(label=\"Input Audio\", sources=[\"microphone\", \"upload\"], type=\"filepath\")\n",
        "      send_button = gr.Button(\"Send\")\n",
        "  with gr.Row():\n",
        "    output = gr.Textbox(label=\"Output\")\n",
        "\n",
        "  def audio_func(inputs):\n",
        "    if inputs is None:\n",
        "        raise gr.Error(\"No audio file submitted! Please upload or record an audio file before submitting your request.\")\n",
        "\n",
        "    # task = \"transcribe\"\n",
        "    # text = pipe(inputs, batch_size=BATCH_SIZE, generate_kwargs={\"task\": task}, return_timestamps=True)[\"text\"]\n",
        "    text = \"hello output\"\n",
        "\n",
        "    return text\n",
        "\n",
        "  send_button.click(\n",
        "      audio_func,\n",
        "      inputs=[input_audio],\n",
        "      outputs=[output]\n",
        "  )\n",
        "\n",
        "demo.launch()\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "iwZcUCJEYhjw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}